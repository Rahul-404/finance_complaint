{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finance Compalint Project -2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import string\n",
    "from nltk import  WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For classification model selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "precision_score, recall_score, roc_auc_score, f1_score, RocCurveDisplay\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# For data pre-processing \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# For Hyperparameter tunning\n",
    "from hyperopt import tpe, hp, Trials, space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rahulshelke/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the data from source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/complaints.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As per Final report of EDA some Fetaures can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>92.367276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <td>89.550798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <td>67.165560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company public response</th>\n",
       "      <td>49.968155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <td>17.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-issue</th>\n",
       "      <td>10.361439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-product</th>\n",
       "      <td>3.200073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.682583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "Tags                          92.367276\n",
       "Consumer disputed?            89.550798\n",
       "Consumer complaint narrative  67.165560\n",
       "Company public response       49.968155\n",
       "Consumer consent provided?    17.506295\n",
       "Sub-issue                     10.361439\n",
       "Sub-product                    3.200073\n",
       "State                          0.682583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending=False)\n",
    "missing[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Company column can be dropped as it contains 4279 unique values which are names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"Tags\", \"Consumer complaint narrative\", \"Company public response\",\n",
    "                \"Sub-issue\", \"Sub-product\", \"ZIP code\", \"Complaint ID\", \"Company\"]\n",
    "df.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <td>89.550798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <td>17.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.682583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company response to consumer</th>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue</th>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date received</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submitted via</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date sent to company</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timely response?</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "Consumer disputed?            89.550798\n",
       "Consumer consent provided?    17.506295\n",
       "State                          0.682583\n",
       "Company response to consumer   0.000272\n",
       "Issue                          0.000082\n",
       "Date received                  0.000000\n",
       "Product                        0.000000\n",
       "Submitted via                  0.000000\n",
       "Date sent to company           0.000000\n",
       "Timely response?               0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending=False)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In `state`, `Company response to consumer` and `Issue` only 0.7, 0.02% and 0.008% of missing values. It can be imputed with Simple imputer with mode strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Date sent to company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-01-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received Date sent to company\n",
       "0    2025-01-16           2025-01-16\n",
       "1    2025-01-16           2025-01-16\n",
       "2    2025-01-16           2025-01-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Date received\", \"Date sent to company\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here dataset has two date feature, `Date received` which is the date on which the complaint was registered to CFPB and `Date sent to company` is when the complaint has been sent the respective company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference betwen date complaint recieved vs data complaint sent to the company\n",
    "df[\"days_to_forward_complaint\"] = pd.to_datetime(df[\"Date sent to company\"]) - pd.to_datetime(df[\"Date received\"])\n",
    "\n",
    "# get the days in datetime days (numeric) format\n",
    "df[\"days_to_forward_complaint\"] = df[\"days_to_forward_complaint\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the days_to_forward_complaint, both the date columns can be removed\n",
    "df.drop([\"Date received\", \"Date sent to company\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature days to forward complaint has information about the duration taken for CFPB to forward the complaint to companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For model to reduce computation time we can use sample of the data for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample data to perform model training\n",
    "\n",
    "df1 = df.groupby(\"Consumer disputed?\").sample(n=50000)\n",
    "df1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "\n",
    "**For Vectorizing**\n",
    "\n",
    "- TFIDF\n",
    "- CountVectorizer\n",
    "- NLTK/Scipy Library\n",
    "- Pretrained Glove\n",
    "- here we can use TFIDF to process\n",
    "\n",
    "**Step for text processing**\n",
    "\n",
    "- Remove Punctuation\n",
    "- Remove stopwords\n",
    "- Lowering Casing\n",
    "- Tokenization\n",
    "- Stemming/Lemmatization\n",
    "\n",
    "- `issue` column has text which has to be preprocessed.\n",
    "- The text needs to be transformed into vectors so as the algorithms will be able to make predictions. In this case, it will be used the Term Frequency - Inverse Document Frequency (TFIDF) weight to evaluate how important a word is to a document in a colleciton of documents.\n",
    "- After removing punctuation and lower casing the words, the importance of a word is determined in terms of its frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create  list of stop words which has to be removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Function to tokenize and  lematize the text column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenize data and remove stopwords\n",
    "def process_text(issue):\n",
    "\n",
    "    # create tokens\n",
    "    tokens = nltk.word_tokenize(issue)\n",
    "\n",
    "    # remove commin stopwords\n",
    "    stopwords_removed  = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "\n",
    "    # remove stopwords including few punctuation\n",
    "    stopwords_removed = [word for word in stopwords_removed if word.isalpha()]\n",
    "\n",
    "    return stopwords_removed\n",
    "\n",
    "# concat the strigns\n",
    "def concat_strings(word_list):\n",
    "    concat_words = ''\n",
    "    for word in word_list:\n",
    "        concat_words += word + ' '\n",
    "    return concat_words.strip()\n",
    "\n",
    "# function to lemmatization words and merge each compliment into  a single space-separated string\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_concat(word_list):\n",
    "    # remove any NaN's\n",
    "    list_of_words = [i for i in word_list if i is not np.nan]\n",
    "\n",
    "    # lemmatize each word\n",
    "    lemmatized_list = []\n",
    "    for idx, word in enumerate(list_of_words):\n",
    "        lemmatized_list.append(lemm.lemmatize(word))\n",
    "    \n",
    "    # make the list into a single string with the words separated by ' '\n",
    "    final_string = concat_strings(lemmatized_list)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data with text processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Row Number 0\n",
      "Processed Row Number 5000\n",
      "Processed Row Number 10000\n",
      "Processed Row Number 15000\n",
      "Processed Row Number 20000\n",
      "Processed Row Number 25000\n",
      "Processed Row Number 30000\n",
      "Processed Row Number 35000\n",
      "Processed Row Number 40000\n",
      "Processed Row Number 45000\n",
      "Processed Row Number 50000\n",
      "Processed Row Number 55000\n",
      "Processed Row Number 60000\n",
      "Processed Row Number 65000\n",
      "Processed Row Number 70000\n",
      "Processed Row Number 75000\n",
      "Processed Row Number 80000\n",
      "Processed Row Number 85000\n",
      "Processed Row Number 90000\n",
      "Processed Row Number 95000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df1)):\n",
    "    text = process_text(df1['Issue'].loc[i])\n",
    "    final_texts = lemmatizer_concat(text)\n",
    "    df1['Issue'].loc[i] = final_texts\n",
    "    if i % 5000 == 0:\n",
    "        print(f'Processed Row Number {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorizing the processed texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', ngram_range=(1, 2))\n",
    "\n",
    "# Get data after vectorizing issue column\n",
    "df_vect = tfidf.fit_transform(df1['Issue'])\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preorcessing\n",
    "\n",
    "**Concat old data with vectorized data from issue text colusmn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, pd.DataFrame(df_vect.toarray(), columns=feature_names)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After processing issue column as vectors, Now issu columns can be removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop([\"Issue\", \"index\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1.drop([\"Consumer disputed?\"], axis=1)\n",
    "y = df1[\"Consumer disputed?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 313)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of Train data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initalize features for transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product', 'State', 'Consumer consent provided?', 'Submitted via',\n",
       "       'Company response to consumer', 'Timely response?',\n",
       "       'Consumer disputed?', 'days_to_forward_complaint', 'account',\n",
       "       'account opening',\n",
       "       ...\n",
       "       'using debit', 'vehicle', 'verification', 'verification debt',\n",
       "       'withdrawal', 'workout', 'workout plan', 'wrong', 'wrong amount',\n",
       "       'wrong day'],\n",
       "      dtype='object', length=314)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>State</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "      <th>account</th>\n",
       "      <th>account opening</th>\n",
       "      <th>...</th>\n",
       "      <th>using debit</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>verification</th>\n",
       "      <th>verification debt</th>\n",
       "      <th>withdrawal</th>\n",
       "      <th>workout</th>\n",
       "      <th>workout plan</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrong amount</th>\n",
       "      <th>wrong day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>PA</td>\n",
       "      <td>None</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>PA</td>\n",
       "      <td>None</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payday loan</td>\n",
       "      <td>IL</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>OH</td>\n",
       "      <td>None</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product State Consumer consent provided? Submitted via  \\\n",
       "0  Debt collection  None                       None         Phone   \n",
       "1  Debt collection    PA                       None      Referral   \n",
       "2         Mortgage    PA                       None      Referral   \n",
       "3      Payday loan    IL           Consent provided           Web   \n",
       "4      Credit card    OH                       None   Postal mail   \n",
       "\n",
       "      Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0                           Closed              Yes                 No   \n",
       "1  Closed with non-monetary relief              Yes                 No   \n",
       "2          Closed with explanation              Yes                 No   \n",
       "3          Closed with explanation              Yes                 No   \n",
       "4          Closed with explanation              Yes                 No   \n",
       "\n",
       "   days_to_forward_complaint  account  account opening  ...  using debit  \\\n",
       "0                          7      0.0              0.0  ...          0.0   \n",
       "1                          2      0.0              0.0  ...          0.0   \n",
       "2                          2      0.0              0.0  ...          0.0   \n",
       "3                          0      0.0              0.0  ...          0.0   \n",
       "4                          0      0.0              0.0  ...          0.0   \n",
       "\n",
       "   vehicle  verification  verification debt  withdrawal  workout  \\\n",
       "0      0.0           0.0                0.0         0.0      0.0   \n",
       "1      0.0           0.0                0.0         0.0      0.0   \n",
       "2      0.0           0.0                0.0         0.0      0.0   \n",
       "3      0.0           0.0                0.0         0.0      0.0   \n",
       "4      0.0           0.0                0.0         0.0      0.0   \n",
       "\n",
       "   workout plan  wrong  wrong amount  wrong day  \n",
       "0           0.0    0.0           0.0        0.0  \n",
       "1           0.0    0.0           0.0        0.0  \n",
       "2           0.0    0.0           0.0        0.0  \n",
       "3           0.0    0.0           0.0        0.0  \n",
       "4           0.0    0.0           0.0        0.0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary encoder\n",
    "binary_features = [\"Product\", \"State\", \"Submitted via\", \"Company response to consumer\"]\n",
    "\n",
    "# for one hot encoder\n",
    "onehot_features = [\"Consumer consent provided?\", \"Timely response?\", \"State\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create columntransformer for transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('SimpleImputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('OneHot_encoder', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "binary_encoder_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('SimpleImputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('BinaryEncoder', BinaryEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# getting data pre processing object\n",
    "preprocrssor = ColumnTransformer(\n",
    "    [\n",
    "        (\"Categorical_Pipeline\", onehot_encoder_pipeline, onehot_features),\n",
    "        (\"Binary_encoder_pipeline\", binary_encoder_pipeline, binary_features),\n",
    "        # (\"Numerical_Pipeline\", RobustScaler(), feature_names)\n",
    "    ]\n",
    "    , remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transforming the data for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit transformer the train data\n",
    "X = preprocrssor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manually Encoding Target Fetaure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually encoding \"Yes\" as 0 and \"No\" as 1\n",
    "y = np.where(y.values==\"Yes\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handeling Imbalanced Dataset\n",
    "\n",
    "**Handeling Imbalanced Target Variable.**\n",
    "\n",
    "- Synthetic Minority Oversampling Technique or SMOTE is another technique to oversample the minority class, Simply adding duplicate records of minority class often don't add any new information to the model.\n",
    "\n",
    "- SMOTE is one of the famous oversampling techniques and is very effective in handling class imbalance. The idea is to combine SMOTE with some undersampling techniques (ENN, Tomek) to increase the effectiveness of handling the imabalnced class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can ba changed as required.\n",
    "smt = SMOTETomek(random_state=42, sampling_strategy=\"minority\", n_jobs=-1)\n",
    "\n",
    "# Fit the model to generate the data\n",
    "X_res, y_res = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "**Here should understand the Various Classification models with default values from these models we can choose top 4 with Highest Accuracy score and processed with Hyperparameter Tunning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function shich returns all evaluation metrics for classification model\n",
    "\n",
    "def evaluate_clf(true, predicted):\n",
    "    acc = accuracy_score(true, predicted) # Calcualte accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculated f1-score\n",
    "    precision = precision_score(true, predicted) # Calculaed precision\n",
    "    recall = recall_score(true, predicted) # Calculated recall\n",
    "    roc_auc = roc_auc_score(true, predicted)\n",
    "    return acc, f1, precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the models which are required for model selection\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbour Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"CatBoostClassifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a function which can evaluate model and return report in Dataframe\n",
    "\n",
    "def evaluate_model(X, y, models):\n",
    "    ''' \n",
    "    this function takes in X and y and models dictionary as input\n",
    "    Its splits the data into train and test\n",
    "    Interates through given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # seperate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    auc = []\n",
    "\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # training set performance\n",
    "        model_train_accuracy, model_train_f1, model_train_precision,\\\n",
    "        model_train_recall, model_train_rocauc_score = evaluate_clf(y_train, y_train_pred)\n",
    "\n",
    "        # test set performance\n",
    "        model_test_accuracy, model_test_f1, model_test_precision,\\\n",
    "        model_test_recall, model_test_rocauc_score = evaluate_clf(y_test, y_test_pred)\n",
    "\n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print(\"- F1 score: {:.4f}\".format(model_train_f1))\n",
    "        print(\"- Precision: {:.4f}\".format(model_train_precision))\n",
    "        print(\"- Recall: {:.4f}\".format(model_train_recall))\n",
    "        print(\"- Roc Auc Score: {:.4f}\".format(model_train_rocauc_score))\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_test_accuracy))\n",
    "        print(\"- F1 score: {:.4f}\".format(model_test_f1))\n",
    "        print(\"- Precision: {:.4f}\".format(model_test_precision))\n",
    "        print(\"- Recall: {:.4f}\".format(model_test_recall))\n",
    "        print(\"- Roc Auc Score: {:.4f}\".format(model_test_rocauc_score))\n",
    "\n",
    "        auc.append(model_test_rocauc_score)\n",
    "        print('='*25)\n",
    "        print('\\n')\n",
    "    report = pd.DataFrame(list(zip(models_list, accuracy_list)),\n",
    "                          columns=['Model Name', 'Accuracy']).sort_values(by=['Accuracy'], ascending=False)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Base report of all models with default parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7794\n",
      "- F1 score: 0.7709\n",
      "- Precision: 0.8001\n",
      "- Recall: 0.7438\n",
      "- Roc Auc Score: 0.7793\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.5631\n",
      "- F1 score: 0.5510\n",
      "- Precision: 0.5706\n",
      "- Recall: 0.5328\n",
      "- Roc Auc Score: 0.5633\n",
      "=========================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7794\n",
      "- F1 score: 0.7587\n",
      "- Precision: 0.8356\n",
      "- Recall: 0.6948\n",
      "- Roc Auc Score: 0.7793\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.5557\n",
      "- F1 score: 0.5187\n",
      "- Precision: 0.5702\n",
      "- Recall: 0.4756\n",
      "- Roc Auc Score: 0.5562\n",
      "=========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_report = evaluate_model(X=X_res, y=y_res, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can use CatBoost Classifier, XGBClassifier for Hyper Paratmeter Tunning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperOpt: Distributed Hyperparameter Optimization\n",
    "\n",
    "- Hyperopt is a powerful python library for hyperparameter optimization developed by James Bergstta. Hyperopt uses a form of Bayesian optimization for parameter tunning that allows you to get the best parameters for a given model.\n",
    "\n",
    "- Grid Search is exhaustive in case of Resource usage.\n",
    "\n",
    "- Random Search, is random, so could miss the most important values. However, there is a superior method available through the Hyperopt package.\n",
    "\n",
    "**Search space is where Hyperopt really gives you a many of sampling options:**\n",
    "\n",
    "- for categorical parameters you have hp.choice\n",
    "\n",
    "- for integers you get hp.randit, hp.quniform, hp.qloguniform and hp.qlognormal\n",
    "\n",
    "- for floats we have hp.normal, hp.uniform, hp.lognormal and hp.loguniform\n",
    "\n",
    "- it is the most extensive sampilng functionality out there.\n",
    "\n",
    "You define your search space before you run optimization but you can create very complex parameter spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning for Xgboost Model\n",
    "\n",
    "**This is a function to minimize that receives hyperparametersvalues as input from the search space and return loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an objective function for hyperopt\n",
    "def XGB_objective(params):\n",
    "    model = XGBClassifier(**params, n_jobs=-1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "\n",
    "search_sapce = {\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "    'gamma': hp.uniform('gamma', 1, 9),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': 180,\n",
    "    'seed': 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
